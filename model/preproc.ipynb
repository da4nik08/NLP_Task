{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f484613e-2f37-4995-84a3-a4ab87928c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b1293e9-986e-483c-ae9c-10306ed7b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path: str):\n",
    "  data = pd.read_csv(data_path)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb196d7d-7eb2-4a8a-bf49-ab3e330f2660",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = get_data(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de3a529-942b-42ef-aa80-eab83f01c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_data(\"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386d8fdd-f40b-46f0-994d-2c2586304716",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(reviews[\"text\"].shape[0]):\n",
    "    input_string = reviews[\"text\"][i]\n",
    "    last_dot_space_index = input_string.rfind(\". \")\n",
    "    last_exclamation_space_index = input_string.rfind(\"! \")\n",
    "    last_question_space_index = input_string.rfind(\"? \")\n",
    "        \n",
    "    last_space_index = max([last_dot_space_index, last_exclamation_space_index, last_question_space_index])\n",
    "        \n",
    "    if last_space_index != -1:\n",
    "        result_string = input_string[:last_space_index + 1]\n",
    "    else:\n",
    "        result_string = input_string\n",
    "\n",
    "    reviews.at[i,'text'] = result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "856b9f6e-a83d-4f0e-b8ae-f84c4bdf3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace = [\"\\n\", '[^\\w\\s]', '\\d+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecfad7fc-29c4-4367-8c97-b601ee55a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"text\"] = reviews[\"text\"].str.lower().replace(to_replace , \" \", regex=True).replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81cc5dc4-a632-4759-8d19-99a105c887b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am not satisfied with the quality of the items i order the items itself had a very cloudy look and the picture isn t as clear because of this this is a father day gift to my husband who lost his mother last year and father says was always a big deals for her because of how proud she was of him and the father he is to our daughter and his step kids dollar for a items of such poor quality is a disappointment '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"text\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccaadb3e-d1f1-427e-9682-af5de7736d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\da4nik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\da4nik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "817c0655-2534-4754-8aa2-8797f25cdcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'each', 'couldn', 'over', 'theirs', 'aren', 'off', 'most', 'hasn', 'ourselves', 'haven', \"mustn't\", 'i', 'then', 'when', \"doesn't\", 'ours', 'y', 'as', 'what', \"you've\", 'of', \"couldn't\", 'weren', 'your', 'this', \"you'd\", 'yourselves', 'their', 'mustn', 'she', 'been', 'the', \"won't\", \"it's\", 'he', 'they', 've', \"isn't\", 'having', 'o', 'if', 'but', 'and', 'once', 'few', 'because', 'them', \"hadn't\", 'll', 'from', 'other', 'being', \"aren't\", 'we', \"wouldn't\", 'both', 'his', 'why', 'does', 'any', 'shouldn', 'in', 'now', 'whom', 'did', 'under', 'below', 'ma', 'it', 'all', 'don', 'm', 'can', 're', 'myself', \"shan't\", 'my', 'here', 'has', 'how', 'wouldn', 'who', 'shan', 'about', 'yourself', \"she's\", 'should', \"mightn't\", 'on', 'me', \"you'll\", 'isn', 'to', 'doing', 's', 'up', 'no', 'such', 'again', 'very', 'against', 'him', 'than', 'are', 'during', 'd', 'after', 'nor', 'so', \"weren't\", 'won', 'where', 'only', 'too', 'into', 'is', 'or', 'mightn', 'wasn', 'with', 'which', 'there', 'our', 'himself', 'those', 'further', 'between', 'an', 'until', 'own', 'have', 'these', \"needn't\", 'through', 'you', \"didn't\", 'at', 'just', 'yours', 'above', 'not', 'while', 'will', 'down', \"should've\", \"you're\", 'had', 't', 'hadn', 'a', 'for', \"don't\", \"hasn't\", 'that', 'herself', 'before', 'didn', 'her', 'be', \"that'll\", 'more', 'hers', 'some', 'same', \"haven't\", 'needn', 'itself', \"wasn't\", 'was', 'were', 'am', 'do', 'ain', 'its', 'doesn', \"shouldn't\", 'out', 'by', 'themselves'}\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "591942a9-e42e-48fc-a069-357e4d6b8f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['there', 'those', 'than', 'too', 'won', \n",
    "              'between', 'all', 'doing', 'such', 'through',\n",
    "              'out', \"couldn't\", 'any', 'why', 'd', 'our', 'off', 'himself', \n",
    "              'itself', 'with', 'more', 'where', 'further', 'they', 'her', 're', \n",
    "              'whom', 'does', 'other', 'under', 'few', 'were', 'into', \n",
    "              'he', 'it', 'herself', 'own', 'do',  \n",
    "              'in', 'we', 'after', 'above', 'ourselves', 'my', \n",
    "              'here', 'this','who', 'to', 'y', 'them', 'about', \n",
    "              'being', 'because', 'having', 'then', \"it's\", 'up', 'down', \n",
    "              'are', 'over', 'if', 'be', 'hers', 'a', 'll', 'from', 'when', 'the', 'have', \n",
    "              'as', 'she', 'how', \"should've\", 'at', 'o', 'until', \"you've\", \n",
    "              'has', 'and', 'same', 'did', 'very', 'you', 've', 'theirs', \"that'll\", \n",
    "              'for', 'both', 'these', 'an', 'themselves', 'during', 'me', \n",
    "              'is', 'ours', 'before', 'some', 'so', 'him', \"you're\", \"you'd\", 'been', \n",
    "              'your', 'shan', 'will', 'or', 'its', 'each', 'what', 'below', 'm',\n",
    "              'yourselves', 'on', 'had', 'was', 'of', 's', 'just', 'while', \n",
    "              'their', 'can', 'which', 'am', \"you'll\", \n",
    "              'now', 'myself', 'only', 'i', 'once', 'by', 'ma', \"haven't\", 'his', \n",
    "              'yours', 'yourself', 'most', \"she's\", 'that']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e7be0dd-7cc4-4549-b450-1a1f0f4ef185",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dc67228-b4f4-46ce-8677-155bc0163b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in reviews[\"text\"]:\n",
    "    words = nltk.word_tokenize(i)\n",
    "    filtered_sentence = [word for word in words if word not in stop_words]\n",
    "    output_sentence = ' '.join(filtered_sentence)\n",
    "    result.append(output_sentence)\n",
    "    #print(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f8bb3bf-73de-463b-b6a2-baebc5d02119",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list()\n",
    "for i in result:\n",
    "    output.append(enc.encode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eb94e83-91b2-4fdf-824c-ed93c6692400",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72218aa5-d17c-4f7f-b1fc-ccd98d1a8e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi leah ordered early give co worker christmas gift however really impressed item came plan show another co worker see thinks outcome thank reaching quick turnaround great service!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28761376-a6aa-47c5-a5a2-792be5227887",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(reviews[\"id\"].shape[0]):\n",
    "    if labels[\"id\"][i] != reviews[\"id\"][i]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a13b290-e7aa-4f43-b91d-f05a600c861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9694ebb4-35cf-40ce-8910-c1616ff94c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labl = labels[\"sentiment\"].replace(['Positive', 'Negative'], [1, 0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddae9943-dd28-4e03-ae34-7af8b6f52817",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5885e02a-22ea-47fb-ac31-55613b6b1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lst in output:\n",
    "    while len(lst) < max_sequence_length:\n",
    "        lst.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22f744bb-4e03-4a53-ab1c-22e3947816ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(file_path, data):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f442d96-7fd0-458d-a6a8-7c9940986845",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl('list_labels.pkl', labl)\n",
    "save_pkl('list_inputs.pkl', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdf3ced6-0fca-4c78-975a-d4667f519da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pkl(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        loaded_list = pickle.load(file)\n",
    "    return loaded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b428f747-d7b6-4c35-9f3e-d7319b76c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = get_data(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "978675c7-4af2-49ce-b388-e010d347e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproces(dataset, column_name, labels_name, max_sequence_length=150):\n",
    "    dataset[column_name] = dataset[column_name].str.replace(r'<.*?>', '')\n",
    "    to_replace = [\"\\n\", '[^\\w\\s]', '\\d+']\n",
    "    dataset[column_name] = dataset[column_name].str.lower().replace(to_replace , \" \", regex=True).replace(r'\\s+', ' ', regex=True)\n",
    "    result = []\n",
    "    for i in dataset[column_name]:\n",
    "        words = nltk.word_tokenize(i)\n",
    "        filtered_sentence = [word for word in words if word not in stop_words]\n",
    "        output_sentence = ' '.join(filtered_sentence)\n",
    "        result.append(output_sentence)\n",
    "\n",
    "    output = list()\n",
    "    for i in result:\n",
    "        output.append(enc.encode(i))\n",
    "\n",
    "    for i in range(len(output)):\n",
    "        while len(output[i]) < max_sequence_length:\n",
    "            output[i].append(0)\n",
    "        output[i] = output[i][:150]\n",
    "\n",
    "    labl = dataset[labels_name].replace(['positive', 'negative'], [1, 0]).tolist()\n",
    "\n",
    "    return output, labl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ff74082-dfa5-40e1-9108-2cd19f7836dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = preproces(imdb, \"review\", \"sentiment\", 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06ec58e9-3c4c-4ffa-8f14-f692ef1779fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewers mentioned watching oz episode hooked right exactly happened br br first thing struck oz brutality unflinching scenes violence set right word go trust not show faint hearted timid show pulls no punches regards drugs sex violence hardcore classic use word br br called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy not high agenda em city home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far away br br would say main appeal show due fact goes shows wouldn t dare forget pretty pictures painted mainstream audiences forget charm forget romance oz doesn t mess around first episode ever saw struck nasty surreal couldn t'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1c467aa-9e42-461f-a76a-a01331d3fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl('y.pkl', y)\n",
    "save_pkl('x.pkl', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d3ad39-d7f2-4b7a-b169-70027c83bf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e90d3-f365-47cd-ac2e-02ffde48c10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
